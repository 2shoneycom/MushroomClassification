{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지, 모듈, 라이브러리 추가하는 곳\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러와서 (train_images, train_lables), (test_images, test_labes) 형태로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준 디렉토리 설정\n",
    "base_dir_train = \"C:\\\\Users\\\\intel\\\\Downloads\\\\trainset(300x300)\"\n",
    "\n",
    "# 디렉토리 목록을 알파벳 순으로 정렬\n",
    "subdirs_train = sorted([d for d in os.listdir(base_dir_train) if os.path.isdir(os.path.join(base_dir_train, d))])\n",
    "\n",
    "# 저장할 이미지 리스트들을 위한 빈 딕셔너리 초기화\n",
    "train_images_dic = {}\n",
    "\n",
    "# 각 디렉토리 순회\n",
    "for idx, subdir in enumerate(subdirs_train):\n",
    "    # 각 디렉토리 내 이미지 파일 목록을 정렬하여 가져옴\n",
    "    image_files = sorted([f for f in os.listdir(os.path.join(base_dir_train, subdir)) if f.lower().endswith(('.jpg', '.jpeg'))])\n",
    "    # 각 디렉토리에 해당하는 이미지 리스트 초기화\n",
    "    train_images_dic[f'train_images_{idx}'] = []\n",
    "\n",
    "    # 각 이미지 파일을 열고 리스트에 추가\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(base_dir_train, subdir, image_file)\n",
    "        \n",
    "        try:\n",
    "            with Image.open(image_path) as img:  # 이미지 열기\n",
    "                train_images_dic[f'train_images_{idx}'].append(img.copy())  # 이미지 복사하여 리스트에 추가\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening {image_path}: {e}\")\n",
    "\n",
    "# 이후 train_images_dic을 사용할 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인 (예시: train_images_0의 첫 번째 이미지 출력)\n",
    "train_images_dic['train_images_0'][0]  # train_images_0 리스트의 첫 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images 딕셔너리에 저장된 각 리스트의 길이를 출력\n",
    "for key, images in train_images_dic.items():\n",
    "    print(f\"{key}에 있는 이미지 개수: {len(images)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블을 저장할 빈 리스트 초기화\n",
    "train_labels_list = []\n",
    "\n",
    "# 각 train_images의 개수에 따라 레이블을 추가\n",
    "for idx, images in enumerate(train_images_dic.values()):\n",
    "    train_labels_list.extend([idx] * len(images))  # 현재 클래스 인덱스(idx)만큼 반복하여 추가\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "train_labels = np.array(train_labels_list, dtype=np.uint8)\n",
    "\n",
    "# 결과 확인\n",
    "print(train_labels.shape)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준 디렉토리 설정\n",
    "base_dir_test = \"C:\\\\Users\\\\intel\\\\Downloads\\\\testset(300x300)\"\n",
    "\n",
    "# 디렉토리 목록을 알파벳 순으로 정렬\n",
    "subdirs_test = sorted([d for d in os.listdir(base_dir_test) if os.path.isdir(os.path.join(base_dir_test, d))])\n",
    "\n",
    "# 저장할 이미지 리스트들을 위한 빈 딕셔너리 초기화\n",
    "test_images_dic = {}\n",
    "\n",
    "# 각 디렉토리 순회\n",
    "for idx, subdir in enumerate(subdirs_test):\n",
    "    # 각 디렉토리 내 이미지 파일 목록을 정렬하여 가져옴\n",
    "    image_files = sorted([f for f in os.listdir(os.path.join(base_dir_test, subdir)) if f.lower().endswith(('.jpg', '.jpeg'))])\n",
    "    # 각 디렉토리에 해당하는 이미지 리스트 초기화\n",
    "    test_images_dic[f'test_images_{idx}'] = []\n",
    "\n",
    "    # 각 이미지 파일을 열고 리스트에 추가\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(base_dir_test, subdir, image_file)\n",
    "\n",
    "        try:\n",
    "            with Image.open(image_path) as img:\n",
    "                test_images_dic[f'test_images_{idx}'].append(img.copy())\n",
    "        except Exception as e:\n",
    "            print(f'Error opening {image_path}: {e}')\n",
    "\n",
    "# 이후 test_images_dic을 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인 (예시: test_images_0의 첫 번째 이미지 출력)\n",
    "test_images_dic['test_images_0'][0]  # test_images_0 리스트의 첫 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_images 딕셔너리에 저장된 각 리스트의 길이를 출력\n",
    "for key, images in test_images_dic.items():\n",
    "    print(f\"{key}에 있는 이미지 개수: {len(images)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 test_labels 리스트 생성\n",
    "test_labels_list = []\n",
    "\n",
    "# 각 test_images의 개수에 따라 레이블을 추가\n",
    "for idx, images in enumerate(test_images_dic.values()):\n",
    "    test_labels_list.extend([idx] * len(images))  # 현재 클래스 인덱스(idx)만큼 반복하여 추가\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "test_labels = np.array(test_labels_list, dtype=np.uint8)\n",
    "\n",
    "# 결과 확인\n",
    "print(test_labels.shape)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 train_images 딕셔너리를 기반으로 모든 이미지를 하나의 리스트로 변환\n",
    "train_images_combined = []\n",
    "\n",
    "# train_images 딕셔너리의 모든 리스트를 반복하여 추가\n",
    "for images in train_images_dic.values():\n",
    "    train_images_combined.extend(images)\n",
    "\n",
    "# 이제 train_images_combined에는 모든 이미지가 포함됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_combined[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 이미지를 동일한 크기로 리사이즈하여 NumPy 배열로 변환\n",
    "desired_size = (300, 300)  # 원하는 크기 설정\n",
    "train_images_resized = []\n",
    "\n",
    "for image in train_images_combined:\n",
    "    resized_image = image.resize(desired_size)  # 이미지 리사이즈\n",
    "    train_images_resized.append(np.array(resized_image))  # NumPy 배열로 변환하여 리스트에 추가\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "train_images = np.array(train_images_resized)\n",
    "\n",
    "# shape 확인\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 test_images 딕셔너리를 기반으로 모든 이미지를 하나의 리스트로 변환\n",
    "test_images_combined = []\n",
    "\n",
    "# test_images 딕셔너리의 모든 리스트를 반복하여 추가\n",
    "for images in test_images_dic.values():\n",
    "    test_images_combined.extend(images)\n",
    "\n",
    "# 이제 train_images_combined에는 모든 이미지가 포함됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_combined[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 이미지를 동일한 크기로 리사이즈하여 NumPy 배열로 변환\n",
    "test_images_resized = []\n",
    "\n",
    "for image in test_images_combined:\n",
    "    resized_image = image.resize(desired_size)  # 이미지 리사이즈\n",
    "    test_images_resized.append(np.array(resized_image))  # NumPy 배열로 변환하여 리스트에 추가\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "test_images = np.array(test_images_resized)\n",
    "\n",
    "# shape 확인\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 랜덤하게 섞기 + 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 인덱스 생성 (train dataset)\n",
    "indices = np.arange(train_images.shape[0])\n",
    "np.random.shuffle(indices)  # 인덱스를 랜덤하게 섞기\n",
    "\n",
    "# 섞인 인덱스를 사용하여 train_images와 train_labels를 재배치\n",
    "train_images = train_images[indices]\n",
    "train_labels = train_labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 인덱스 생성 (test dataset)\n",
    "indices2 = np.arange(test_images.shape[0])\n",
    "np.random.shuffle(indices2)  # 인덱스를 랜덤하게 섞기\n",
    "\n",
    "# 섞인 인덱스를 사용하여 test_images와 test_labels를 재배치\n",
    "test_images = test_images[indices2]\n",
    "test_labels = test_labels[indices2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터 정규화\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모델 구축하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 생성\n",
    "model = models.Sequential()\n",
    "\n",
    "# 첫 번째 합성곱층 + 풀링층\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# 두 번째 합성곱층 + 풀링층\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# 세 번째 합성곱층 + 풀링층\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten층\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Dense층\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# 출력층 (100개의 클래스를 위한 소프트맥스)\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "# 모델 요약 출력\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # 정수 레이블에 적합한 손실 함수\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
